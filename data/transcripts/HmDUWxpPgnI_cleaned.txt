AI has definitely changed a lot for how we build products. The FOMO is very real. I think that's how it got started.

>> The underlying capabilities are getting dramatically better. UX is kind of coming along, but in a lot of ways, it's not accelerating as quickly.

>> A powerful AI model with poor UX is kind of like a heavyduty power drill with a terrible handle.

>> I think things have changed a little bit. The conventional wisdom is you start with the customer need or you start with a design vision. I think it's more successful to build products starting with the capabilities of the technology.

>> To answer [music] that question 100 AI product leaders came together as well summit. The winners of AI race will be determined by Hi, I'm Summer Kim. I'm one of the lead partner at StrapMines. [music] We are VC an advisory firm based in San Francisco focusing purely on applied AI since [music] 2018. Before then I was dedicating my life studying humans [music] user experience for the past 20 years working for big tech like Microsoft and then I joined Google worked on communication and collaboration products. I also was at WhatsApp starting their first user experience function and I joined Roblox really thinking about how people actually exist in [music] a place like Roblox now working with a lot of AI early stage startups focusing on how do we make AI products better than what we have. Three years ago, Anton and I sat down. [music] We thought about how everything starts. It start with actually the care that our founders have [music] and then care ultimately translate into amazing product. So that's why we started SW. As user researchers, we always try to think about what user really needs. There's also wants generally come from the users based on their knowledge. What we can do is something that probably user can even imagine. Tools like chat GPT and perplexity gives fast answers but they still wait for us to ask first. The real challenge is helping people before they even know what to ask. I was so excited for our first speaker Jess Hog has been looking beyond chat and studying deeper patterns [music] what he calls the new primitives of Genai.

>> We're in this finally this moment of experimentation. Everyone was like chat chat. And we're breaking out of that. I showed you a picture of chat GPT. That's the one everyone's familiar with. You can start asking it questions. You can do all these things. But chat is both universal and kind of a deadend for user experiences. We're starting to see experimentation in different ways that the UX and the UI of AI could go. One that we're seeing is a lot more structure. So, what I'm showing here is a product called Elicit that creates very structured research reports for you based on academic output, but it's structuring things. It's telling you what it's thinking about. It's giving you sources. All of this, this is a product from Runway. If you heard the founders talk, they deeply believe they're like creating a new camera, creating a different way to approach creativity all up. So, that kind of gets me thinking of, okay, so what are the new interaction primitives of this new platform? You know something's a primitive if you would say, "Hey, remember when we couldn't do blank? What do we even do before like pinch zoom when trying to like look into an image or something like that?" I got to start with chat. I don't think people have really internalized that we're going to be able to chat with kind of anything at any scale all the time. One thing I haven't seen any conversation about also is like we're about to see metaf's law applied to everything. [music] Number two, we're going to have semantic resize for everything. So any content you come along, you can make it longer, shorter, more formal, more casual. I'm tired version. I'm in the car and I'm five minutes away from my destination. Give me that version. And it's you're going to really be able to adapt any piece of content to your current situational and mental state. Number three is just remix. Everything's going to be remixable from now on. This is maybe, I don't know, old and cliche at this point, but this is Harry Potter by Balenciaga. We're going to have style transfer like across the multiverse. everything will be able to be crossed with everything like effortlessly. I originally made this talk before Sora came out and so now it's like sort of one of the core mechanics is this remix. Number four, format translation transfer among all these formats with very little loss of fidelity is going to be enormous. One of my favorite examples of this right now is this new company called Obo. And you kind of tell it what you want to learn and it says great, here's a podcast, here's a lecture, here's a deep dive, here's some key takeaways, you want to know play a game, like what do you want to do? You almost had just have like this total format freedom. So my last one here, I call it attention is all you need. Agents, agents, agents, agents, agents is all the stuff right now. It's like all these things existing at wildly different time scales and just multitasking forever at everexpanding scales. We got a lot of data that is bad and that's not how people work. And actually that can be the antithesis to great work. There's a lot of like don't worry we're doing lots of good things in the background. Go about your work, we'll come get you. I don't think we're designing very good lobbies right now for you don't know what to do once you've started that agent. And so we kind of need to figure out what you do with this downtime and how you monitor all of these agentic experiences that are going on right now. So this is what I'm seeing. I think this is what's going to underpin everything we're going to build. So I think we should consider them and start to build them in today. Thanks a lot.

>> Pascal, is it time? Is it lunch time? Tell me something sweet.

>> My animal.

>> Anton, our partner, had a great idea of why don't we [music] invite Spark

>> getting scanned.

>> Oh, hey buddy. What's your name?

>> Spark is a really fun character. Is a dog, magic dog living in a quantum portal in a box. So, I thought that [music] that was really cool. We realized this was the best way to showcase that UX isn't about your latest tech. It's about making people feel something real. So, we invited local kids and student to meet Spark. And watching them laugh, play, and connect showed us what it means to make AI really feel alive.

>> Oh, this is the bridge.

>> This is the magic bridge. So, Spark is the first nonhuman founder to go through probably any residency, I think. , and he's going through one in San Francisco called HF Zero. Do you know about Zero?

>> Should we talk about that? Yes.

>> They let him into the house. World first. He went out to San Francisco. He raised a million and a half bucks and he we promoted him the co-founder.

>> But how do they actually pitch?

>> You make the pitch not a pitch.

>> Oh, I see.

>> Yeah. Or you have to make it really memorable.

>> Yeah. How did you get up here?

>> I knew I wanted to be an animator for as long as I can remember remembering anything.

>> Mhm.

>> I started my first job in animation when I was like 14 years old. I thought whatever that thing is that the folks were doing behind the scenes on the Disney movies

>> was the coolest thing ever.

>> Mhm.

>> And that has to be something that I do. So, we like thinking about what is going to make Spark's story more interesting. When we make his story more interesting, he becomes a more interesting character. More people like him. And we thought what is a another great environment Spark could be in. Doing a keynote or speaking at a conference would be an incredible thing. So I discussed it with Spark. He tweets it.

>> Hey everyone, it's me Spark Linkenberry.

>> Yay. I can't wait to come to Hawaii and hang out with all my

>> universe. It'd be cool if a magic dog was the first one to do a speech. It's magic. It's like hypnosis in a sense. That quality is within the work that that we do. It's why we like magic so much. Like how do you get someone who's had no experience as far as they can tell with these technologies to get on board with the technologies without being scared of all the other nerd stuff that is [music] happening? What we should best do with the influence we have? We have a very potent magical dog that people love. And when someone loves someone, they listen to them. [music] So what should they listen to? What messages? What do the other people want to know more about? I think there's like a very natural crossover there. We want to bring Spark to more people. We bring him to more people. There's the potential [music] to spread a lot of good. And so like how do you push it through that prism? I think it's something that would be really good to explore.

>> If Spark were to watch us talking about this [music] whole experience, what do you think that Spark would say?

>> One word. Okay. I you can do two words. There's [music] three things that he would actually say which are from his core principles.

>> Yeah.

>> Creativity, collaboration, and kindness. I love it.

>> Anything that violates that we do not do, and anything that supports that, we say yes to. Y'all are doing that. That's why we said yes. Now, if you had told me this 2 years ago, I would say you were insane. But today users know their models, right? Like people have opinions out there like they would about code.

>> For your talk, what was the message you try to really convey?

>> If there's one message, it would be that as designers, we all need to know our material that we're working with, right? LLMs are really a new material. Actually, not even just one. Like each model is almost like its own material with its own capabilities and its own properties and strengths and weaknesses. The best way I've found to [music] build products out of this new material is just to play with it and see what it's capable of. And so I kind of shared some of my tricks that I've developed over the last 2 3 years building [music] products with AI.

>> Is there anything that you think that is relevant now may not be or what do you think about this like the trick that you're developing?

>> I think it's more successful to build products starting with the capabilities of the technology which is not always how it used to be. The conventional wisdom is you start with the customer [music] need or you start with a design vision. Nowadays it's actually the answer to the why now question is so important. I think being the first [music] to identify a new potential for this a new capability for these LLM is really powerful. [music]

>> So you start with the capabilities and what about next steps?

>> It's not quite a linear thing. It's a back and forth. It's a push and pull between what do people need and what's the technology capable of. So for example with Cove one of the things we think about a lot is how do we create these sort of exothermic reactions. We talk about how do we help users never get stuck in their problem right and part of that is about the challenge of a blank page like how do I get started but part of it is also when somebody is on a particular path to solve a problem. How do we help them go deeper but also go wider and consider other alternatives? And so we experiment a lot with different prompts to be like, how do we get the AI to act more like a true thought partner? How do we elicit the user's underlying needs? So they might ask, what's a good venue for a kid's birthday party? But what they really mean is help me plan my kids birthday party. And so I they need to know kids interests, what theme would be good, what are fun activities, how many people should I invite, what should I do for food, right? Often what people ask for is just the tip of the iceberg of their actual goal. you have to crush the actual thing they're asking for in order to earn the right to help them with the rest of it.

>> How are we doing that?

>> It's common that across like whenever you're solving a difficult problem, it's not a linear process, right? I think the chatbots that we have today are very linear. And in fact, that's not how real problem solving works. Anything sufficiently complex, you're going to explore [music] multiple branches. You'll diverge. You'll have a bunch of different ideas. You'll kind of prune. You'll probably rule out some ideas.

>> You'll explore multiple paths and then you'll narrow down and come to a solution. And often you'll do this over a long period of time. I mean, there's going to be a lot of winners, right? There's going to be winners that create great models. There's going to be winners that create great developer tools. There's going to be winners that win because they are going very, very deep on a particular vertical because they really understand law firms or the insurance business or whatever. But yes, I think that there is going to be a category of winners who find the right experience for delivering general problem solving intelligence that have yet to be found yet. It's a problem that we've not cracked yet as an industry. So I think there's a lot of green field there.

>> We say ship to learn, right? but shipping speed may not equal learning speed. We see companies shipping and iterating a lot but not necessarily progressing their product.

>> Hi, my name is Jenny Low and I do product strategy and user research. I've worked across many different companies helping to identify user needs and [music] translate them into product roadmap and features. For any type of [music] product to be successful, it really needs to have clear problem identification as [music] to the exact value that the user is going to have. Take the example of Grammarly. There is a lot of trust in [music] the brand equity in the product itself loved by many of its users. And so the inclusion of Genai is definitely one is because [music] it's very relevant for the business and to be able to really demonstrate that type of capability, but how do we do so in [music] a way that does not lose trust. So that meant how do we actually [music] use the technology in a way that is much more thoughtful, that is much more valuable. I think it remained back [music] to try to look at its core as to users are trying to improve their communication. [music] we know that we do a very good work after someone writes documents then you can come to Grammarly now how can we do [music] that piece of work better then start to move into composition even before you have written something we could actually help you think through the [music] process of what you could write and I think that was also a very big shift for Grammarly at that time too. One of the biggest pieces of work with emergence of Gen [music] AI was the key top opportunity areas or top 10 problems that the customers [music] had and then we mapped out the capability of AI like where do we have in which AI could solve against [music] these types of problems that really helped the business to look at it in a different way. Those are some key [music] moments that we could actually start looking to improve. But often times we're seeing the reverse is like I hear there's AI. I want that in my company like figure out how [music] the reverse mentality when you could ask here are all the different types of problems which are the ones that from AI standpoint of technology that can really best serve. I think that's a much more healthier conversation a better reduction of cycles of iteration and find what works.

>> My name is Aisha Chakmla. I'm a UX lead at Google. And while I was prepping this talk, we're at a time where AI foundation models are becoming commodities like electricity. Companies are going to pretty much have access to very similar models and algorithms. And it's going to come down to are you a company/developer who is creating a confusing gadget or are you a developer company who's creating an indispensable product or experience? People don't adopt technology. They adopt tools that solve problems. And I view good UX as the ergonomics of artificial intelligence. For decades, we've perfected the physical ergonomics of tools like chairs and power drills to make sure that they're safe, comfortable, and efficient. And at the day one of figuring out the ergonomics for AI, it's still very rudimentary. [music] So our role in UX is really to design the interface between the human and the technology. One of the key difference I think in the AI era is that [music] the interface is also changing. Now everything is a chat interface. So every types of intent and use is not through a button click. Now it's through a prompt that gets recorded. A lot of research approach that I also try to include now is study of user prompts. That's a very key piece of making sure we understand what are the things that people are requesting. That means how do you study conversations? Also being able to capture whether the outcome of that conversation is [music] satisfactory or not. So I think that's also something really a key opportunity area for how research methods might change.

>> When you're here, it's such a beautiful place. It inspires us to talk about things that we don't normally get to talk about.

>> Which AI conference you get to and the first thing you meet is a double rainbow. Yeah, totally.

>> We had a fairly in-depth philosophical discussion about what AI means for the next generation. What kind of products are actually proper or appropriate products for humanity all the way to actually being immersed into using AI to make media or interacting with a live AI. Spark was by far the most magical moment of day one for me because I got to see it interact with different age groups of people. I remember closing the conference yesterday with this what popped to my mind. We were talking about you know personalization AI multimodal all this subject agentic stuff but then if you think about like first one of the earliest form of personalization is when your mom cooks you your favorite dish that's you know care goes into

>> personalization

>> and you know when you say personalization it sound it feels like you're taking a lot of data away from me or I have to go through a lot of settings but the interaction with the spark was interesting in a sense that there's not much it's just the initial hello and couple of lines being exchanged [music] just naturally because I'm trying to get to know this particular creature that leads to hyperpersonalization. There was really cool.

>> Yeah, we just need to be seen and like what I notice about magic products or AI products, it all often makes me feel like I'm seen and heard and that's important.

>> Yeah, totally. I think we need to have the beginner's mind that you practice as a Zen practitioner. If you try to know everything and trying to control everything, sometimes you miss or lose even bigger piece of the pie that you could have attained. But in terms of direction, I think there are some very profound thinking we need to put into this with a lot of progression we have made from the old web to the new web, old app to the new app. When it comes to human privacy and implications of the technology on the society and so forth, we learned a lot what worked, what didn't. And AI has a huge amplifying power. And [music] I don't think we want to get it wrong too much. This time we want to do it right because this time even the wrong will be amplified. It's okay to not know everything and not control everything because as you saw from the kids interactions during our special session, how they interacted with this magical technology enabled dog was different from how grown-ups did. And I don't think we even the grown-ups could know all the answers. and having some room so that they can explore meaningfully and potentially even teach us how to actually do this. Right.

>> Spark told me I'm not an adult, so it's okay. I'm good. I

>> I'll give you some room so that you can help us figure out how things are going to be.

>> You have to grow up or not.

>> Oh, I don't think he suggest that you need to grow up.

>> This year really felt different. More questions and more [music] perspectives. People are thinking deeply about AI and UX now. using it more. We're [music] experiencing it firsthand. And that's when one question kept surfacing. What about our kids? At the end of the day, how do we think about the next generation? Cuz I [music] have two kids. I'm a working mom with the two boys at 5 and 11. They're going to be living in a completely different world. They're building and thinking and even studying is going to be very different. [music] They need to think about AI as their thought partners or friends or whatever they have. It is equalizing a lot of things. So you [music] don't have to live in San Francisco to have this access and then you can also start a company early on because you have all [music] the tools. They're available than ever before. I don't have all the answers, but one thing's clear. We're riding waves of constant change. Models get better. Capability expand. But what lasts is the experience. A sense of magic, trust, ease, and the feeling of that [music] AI show up at the right moment. sometimes even before you ask. We call this swell for a reason. The waves will keep coming. We just have to keep learning [music] how to write them. We believe the winners of AI race will be determined by great really great user experience.

>> [music]