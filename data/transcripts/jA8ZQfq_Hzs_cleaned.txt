I think we have AGI.

>> I think we have artificial general intelligence. We really haven't.

>> You hear these 95% of projects fail, but like you know like that's that's that's actually what you want. I

>> I think the LLM is a commodity. People are not saying that, but it is a commodity. Like you can get gas from this gas station. You can get gas from that gas station. Doesn't matter. Just compare price.

>> Is AI in a bubble?

>> There is an AI bubble. Okay. So then Glean is also in the bubble. Everybody's in the bubble. No, I would say there is a bubble. I would say those three camps.

>> Yeah. There's a super intelligence quest camp.

>> I would be very worried there. There's a second, the researchers doing the, you know, that's definitely not in a bubble. They're like the

>> They're sober.

>> Yeah, they're they're super sober. Nobody cares about them. And then there's Right. And they're probably the ones that are right, unfortunately. And then there's the third camp, which is us trying to make this valuable. We're not in a bubble in a sense that we're not spending huge amounts of capital on what we are doing. we're just trying to get actual economic value inside of these organizations. two legendary builders, Aliant. I'm so thrilled to get into this with you because both of you have seen every super cycle I've lived through. Internet, mobile, cloud, data, and AI. Not just through the super cycles, but also through the hype, the trough of del dis disillusionment. And this time it's different. Today we're going to chop it up on the state of AI. You know, let's let's start with a 20,000 ft view. Take stock of where we are. AI, we've seen consumer AI, billions of users. Chad GPT said the guns went off three years ago. Cloud perplexity. Chad GPT people use it in the room. On the SMB and developer side, you've got hundreds of millions of users with cursor and codeex and cloud code and and so on. Enterprise, on the other hand, there's a lot of divide. It's hard to see a lot of fog of war. On one side, you've got models that are earning math benchmarks and science benchmarks and engineering benchmarks. But on the other side, you've got the MIT report that's saying 95% of AI deployments don't work. What's the reality? Bridge that gap for us. Lay it out as you see it. View from the top. So, so I think first of all, I think we should know that people use AI in their personal and work lives both. So there's not so much of a divide like you know everybody in your company is probably using chat GBD and claude and other tools on a daily basis. the the thing that I feel you know is happening in enterprise is you hear these 95% of projects fail but like you know like that's that's that's actually what you want like you like when you are actually experimenting with new technology if all of all of your projects are failing that means you didn't just not enough you know at the moment. So, so I think when I read the study like it was not a surprise for me. , you know, we're going to actually see hopefully like you know, similar stats next year too. , because we want everybody in the industry to be to be really eager and experiment and actually figure out like you know how to make how to actually make you know get you know get benefits from this technology.

>> This would make you guys by default the 5% of AI that is working

>> which is one in 20.

>> Maybe you go to the 5%. what is a use case that is working and not just working like it's like saving me time but like it's working and it's transforming my company something that you can take to the bank to the CFO while the CFO will notice it but the legal won't shut it down

>> I mean look we're seeing a lot of use cases that are working it's just that you know you just have to it's not just you can just unleash the agents and it just works

>> it's an engineering art like if you're going to have a company that's going to be really differentiated like like my company or your company or anyone's company and you want to beat the competition, you can't just like, you know, quickly put something together and think that, you know, the your competition is not going to do the same thing. So, that's going to be, you know, something that needs evaluations. It needs something that, you know, you're going to productionize. It's going to take effort. You need a great team around it. But, we're seeing a lot of them. Like, I'll give you some examples. , Royal Bank of Canada

>> built agents with us that basically take as soon as an earnings report comes out. So equity research analysts their job is to put together these you know reports that say like you know this is a buy this is you know hold and so on. the agent goes gets the earnings report gets all the previous earnings reports get all the competitors earnings reports gets everything that's going on in the market does the full analysis the news everything puts it all together and it can get the equity report out in 15 minutes from the earnings call. Industry standard is two hours. Of course, it's going to get commoditized and others are going to do that as well, but that's actually really important use case that we're seeing in finance.

>> , so that's like finance example in finance, right? It's like and there's lots of examples like this. Sifting through hundreds of thousands of documents, SEC report, so on. That's finance. , let's switch gears. Let's go to healthcare. Healthcare is completely different. In healthcare, we have a you know a customer Merc that in the life science space created a model called Teddy. Teddy stands for transformer enabled drug discovery. And this is a transformer model kind of just like large language models that can predict the next word, but it instead can figure out which genome is missing if you remove a genome. So it really understands the gene regulatory network and can really start telling you what's happening with gene expression and so on. So this is really important for drug discovery

>> is the beginnings but this is going to actually help us do things that we couldn't do before.

>> Let's pick retail also. So I'm picking different healthcare is one I gave you finance right the RBC one.

>> let's go to retail 7-Eleven

>> agents that completely automate the marketing stack. Actually the marketing stack is going to get disrupted pretty heavily. Mhm. So these agents can basically prepare they can segment the audience like this segment wants to hear this and they can prepare all the marketing material that's like directly targeting you guys and they can put the campaigns together and do that. 7-Eleven was doing this before as well, but you know this and we're seeing this at data bits as well. More and more is being done by agents and being automated. So you can just do it faster and you can segment more fine grain because before you had to create the content for the groups that was a heavy content creation was something that was human manual labor.

>> Now you can actually do that much more like you can have all your web materials completely customized for a target group. So

>> these are examples where it is working. There are also lots of examples where it's not working. Even with data bricks, we're not just the 5%, you know, we have that some of that 95% too, but some examples are where it's where it's where we're seeing success. Ali, follow up on that of these are great examples. Thank you. Maybe if you if you were to take it a layer up, what is common across these use cases or these organizations or these CIOS that's making these use cases work? Is there something that we can pattern match?

>> Yeah, look, I think the LLM is a commodity. People are not saying that but it is a commodity like and you know when I talk took econ classes commodity was when it's interchangeable like you can get gas from this gas station or you can get gas from that gas station it doesn't matter just compare price LLMs have become that way like it doesn't really matter this one is better right now next week that one is better you can't even keep up anymore right what's happening so they're a commodity so it's not about that it's really comes down to your company what data does your company have that's special that your competitors don't have

>> can you leverage that and can you build AI that really understands that data cuz that's not a commodity. There's not a AI out there that understands all your business processes in your company, your secret sauce and your data. That's not a commodity. In fact, that's closer to the 95%. It really comes down to that. Or if you have a complicated process that just your company has, this is how you deliver your product and services in your company. And it's you know, it's that portion can be disrupted with AI somehow. If you can do that now, you can get ahead of your competition. But it comes back to what makes your company special. Unfortunately, a lot of companies are just building commodity stuff. Like you should not be building that because it's a thing that every company can do. It's not special to your company or to your that's that's I think the problem in a lot of the industry. another problem in industry is a lot of demo wear. It's really easy to make cool demos with Genai and you know therefore we're seeing a lot of cool demos but that's all they are.

>> Yeah. Well you know something we say around at Ultimator quite a bit is your AI strategy starts as your data strategy. Yeah. So you got to get the data house in order first

>> and you know there's a lot of reasons for use cases that are you know we were trying we're not working. Maybe give us an example of the 95% of an AI bet that either of you had at data bricks at glean that did not work out and why it didn't work out. It's actually interesting thing you know with engineering today is you build systems and never before have we been in this mode where you start with a great idea and it doesn't seem like a good idea anymore like within two weeks you know because we see a new development that happens. So there are we have like numerous fail failures in in engineering on that front like you know for example some of our fine-tuning work building models for specific use case within our product like you know didn't didn't really pan out for us and ultimately the choice was that you know we can go with already built models whether they are small open source models hosted on data bricks or one of the large you know foundation models the but internally like you know from a corporate you know use cases perspective So actually like we you know we are also like in many ways in this mode where a lot of our work actually like I would not say like fail but it actually takes much longer than you know to actually generate success. you know there are you know we actually trying to automate a lot of our business processes internally and like for example like you know one thing that I want is in our company I want everybody to actually know exactly what their top priority for the week is what they want to work on and maybe you know we want an AI agent to actually first tell them what their priority should be and we want it all to be documented and we want a system which actually then you know rolls it rolls it all up and I get a view every week where I can actually quickly see you know what are all the different people working on in the company and are they align is that aligned with you know what I want them to work on

>> and this a simple thing like you know companies have always u tried to actually have this you know as CEOs you always want it and it's always hard to make happen and we thought that AI would simply just like you know magically do all of this work because you know like it has all the context has all the context inside the company to make it happen but I still don't have it so, so things do take time to actually you know to Ali's point like you know there is AI is just one more tool that you have in the toolkit. It does not suddenly make building complex enterprise systems you know you know like it doesn't make it like that you can you know build it up like in one day doesn't

>> you know the last time enterprises got this excited about a tool was called RPA.

>> Mhm.

>> And we know how that ended. it unfortunately fizzled out and you know somebody in the audience yesterday is like hey how is this time different from RPA it seems like the same movie bigger budgets better actors what's different this time how is the nature or the architecture of the the technology different from the previous automation cycle either of you

>> yeah I mean I first of all RPA like it didn't take you know it didn't capture my attention at all so I have no so I actually can't you know

>> what is so I think I thing like I would not compare these two technologies at all. Like you know you know what we what we're seeing now with AI is so fundamental you know it's it's you know it's is the you know when when we saw it first it was basically magic and we couldn't believe that this is a machine that is doing this work. machines just simply cannot do these kind of things you know that we saw them do like riding on their own having emotion understanding emotion

>> so it's a you know it's it's fundamental it's different and the and that's why like you know I don't think you know we this this technology is going to fizzle out and it's not like you know you don't have to be like a financial expert or you know a you know like sort of a deep thinker on business. This is this is obvious stuff like you know all of us know all of us feel it. All of all of us can see the capability of this technology and we know it's special and it's going to be it's going to be around.

>> Yeah. You want to hear my RPA

>> please. You know I mean it was rule based and the problem with it especially if you're you know you're you want something that automates what's going on on your desktop and automate the work that's happening. It's just that there's too much unexpected things that happen and it's just hard and brittle to set it up.

>> Mhm.

>> It wasn't learning ever.

>> So there was like zero learning. It was like you tell it exactly here are the rules and if it got something wrong you you need to go and go back and expand the rules. Here you have something that's learning

>> right so it can it can improve and it can generalize and it can understand the patterns and do pattern recognition. so that's the fundamental difference between these two%. Now there has been many startups that have failed

>> in the generative AI we're going to replace RPA with generative AI models. There's many startups that failed actually that I know of like pretty some high-profile ones. It's because the paradigm we live in today with AI is there's still problems. The biggest problem is that

>> you bake a model and that's where it's learned everything it needs to learn and then you freeze it

>> and then you launch it and then maybe you give it some context but that's it. It's frozen.

>> So there in lies the problem that you know we need we need an AI that really can sort of continue learning while it's using the desktop and clicking around. So I do think this problem is hard to to nail but I think Arvin is right that

>> it's like there's no comparison at all. It's like rule brittle rule based stuff versus learning agentic system. I think it's going to nail it perfectly. But we haven't really nailed computer use yet.

>> Yeah,

>> working on it. The number one shift is this move from

>> if then else statements

>> to a more generative solution that figures out the solution.

>> and so you're trading breath for maybe determinism. that seems to be the difference and you know there's a lot of CIOS in the rooms we've got here and they've got budgets coming up to plan. if you were giving advice to them of like hey based on everything I know from my customer base here is one thing or two things that you've got to figure out and align incentives on or it could be a reliability problem or or design. What advice would you have for CIOS who are thinking about their AI budgets right now?

>> Well, spend more.

>> Put it on glean.

>> Spend more. Yeah, put it on glean. But the I think the like one thing you know which which is important in AI market today is that it's very new and there are many players. In fact every every software company is also an AI company now. you can go and check their websites. So, so the I think it's it's just hard to actually figure out where to allocate those budgets and what we tell people is that I think the winners are yet to be identified and so experiment with more vendors do shorten shorter term contracts and and you know while that's easy to say it's hard to actually implement because every product that you try has you know it's a cost that you have to pay to make make it sort of even tested. So, so you have to also pick products that are easy to test. I mean, those are the ones that don't require you to, you know, spend the next 6 months trying to implement something and you no idea what's going to come out after that. Like, you know, the products of today, the products that are built with the right AI, they should work, you know, , very, very quickly for you.

>> Crawl, walk, run, we're going to take a peek into the future. Shifting gears, you know, one of the things that keeps investors like me up in the nights is a quarter trillion being spent on Nvidia on the semi side of things. Assuming that is just 50% of the capex, you're spending about half a trillion on capex and then you've got to earn about a trillion dollars of AI revenue for all of this capex to be worth it. This and just to put this in context, the entirety of the software industry earns about $400 billion of revenue. This seems like a physics problem at this point. How do you how do you think this plays out? You know, you've got you've got to make about a trillion dollars of revenue to justify this present spend that's already happening. How do you think this shakes out? maybe we start with you, Arvin.

>> wrong person to start with, but you know, I'm an engineer and I shouldn't really, you know, think too much about who's spending what money. Like, you know, we're here to build our product and add value. So that's so in some sense you know I've not really thought too much about this problem but but if you think about AI the you know AI is not actually you know extending software in a marginal way it's a it's it's a different product and in fact you know it's actually going to grab a lot of revenue that actually today is in services industry which is 25 times larger than software industry so there's there's a lot of spend that is going to move I mean that the spend that you see happen on AI is actually sort of you know those service dollars that are converting into AI or software dollars. and I think the but with that said, you know, maybe maybe you have a more informed view on this.

>> By the way, I do think that's that's just to build on. You said, you know, I'm an engineer. I want to just build something that's cool. I do think it's not binary, right? It's not like, okay, so the physics doesn't work out, so the whole thing will collapse. No, there's going to be things that work

>> and so it is a good idea to continue focusing on the stuff that is obviously already working. Continue expanding on that. M

>> but I think if you zoom out I think there's like three paradigms or three kind of camps

>> and I put Arvin in the third camp. I actually put myself also in the third camp but let's start with the first camp. I think the first camp is this quest for super intelligence

>> camp and it's you know I think all the frontier labs are doing this like you know all three four or five of them however you want to count them and I think it's really still being a lot of it comes from the scaling laws mentality

>> which is whoever has the most GPUs and the most data is going to win the quest for super intelligence which is kind of intelligence that's like on almost like godlike it leads to recursive self-improvement of the AI which then once you have that it can cure cancer and solve all economical problems and we can probably 10x GDP over a few years period of time. So what the hell are you talking about that there's a physics problem like it'll anything any of your cost equations are going to pale in comparison to the economic value that this thing is going to provide. So that's like one camp and the way they're developing it is bigger and bigger clusters more and more energy and that's how they're going about it. , and that's where most of the capital is going, right? Right. That's not your that's not the kind of capital you're spending or I'm spending, but that's that camp. , and then how do they know that they're succeeding? They're not just like, oh, just trust us. They're, you know, very smart people working on this. So, the way they're approaching it, they're saying, you know, we'll throw the hardest questions we have at the whatever AI we have now. And if it nails them and we're making really rapid progress, so what's your problem? Like, we're like, look at math olympi. We're like nailing these math olympiate problems and physics olympiad and programming contest is like better than any human being. So like that's what they're throwing all the most intellectually challenging. There's a second camp which are the people that created the original technology the scientists who created the technology got the

>> the computer science Nobel Prize for it. It's called touring award

>> and that's you know Rich Sutton who created reinforcement learning which you know a lot of this stuff is built on. You have Yan Lakun who was one of the three founding fathers and many others. They have for many years actually I've been you know I asked them for years they've been saying that that first camp is not gonna that's like not even the right approach is their view they're like no that's just like auto reggressive next token prediction it's just probabilistically predicting the next token that's not how and usually they will say that's not how humans learn that's not how animals learn you know that we operate in a different way your brain is not that way and one example is that you know even a child learns very quickly to walk and talk and do things with very little data compared to, you know, like certainly no child is reading all of the internet's data four times over before they learn to speak. So anyway, so that's like camp number two. Those guys, by the way, they say it's 20 years out.

>> So they're saying, "Hey, it's a physics problem and it's going to take 20 years to get there."

>> Which to me it's like I don't know like leave me alone. let me do research. Third camp, which is I think what we are in is I don't think we need super intelligence. Like you know, I don't think we need that super intelligence right now. Maybe they'll get there. That's awesome if they do. But I think we have AGI.

>> I think we have artificial general intelligence. We really have it. We absolutely have it. It's like anyone who says we need to get to AGI,

>> that's like it's it's a it's false premise to start with. We already have AGI.

>> I came to United States in 2009 at UC Berkeley, not far away from here. And I was in a AI lab. It was called AMPL. The A was for algorithms and AI machines and people. And these are all AI people. And back then the definition of AGI we had we already have satisfied that like I know the discussions we had and I actually went back to some of those folks to see like is it just me or what was the sentiment back in 2009 and everybody that I talked to said yeah that's by those standards we had AGI but we've changed the definition now we have those definitions you know ads so for 30 40 years we had a definition of AGI we've already hit that now we're changing it and moving the goalpost but very obviously we already have AGI just use any of these LLMs and have it do some reasoning and certainly it's smarter than many a lot of friends that you have that right like you know let's let's not them or co-workers or whatever right so you already have AGI now we're like haggling over exactly how smart is it you know do you have a friend that's smarter or not so if we already have AGI we just need to make it useful inside the enterprise we need to just expand that 5% to be 10% 20% 30%. So that's why I think Arvin's answer is actually a good answer like we have the AI we need. Let us just focus on solving the actual problems inside the organizations and I think we can already that's that's enough to automate a lot of the tasks and get huge economic value out of it. We don't actually need super intelligence for that. That's good idea. If the super intelligence guys nail it, amazing then we've cured cancer. if they don't hopefully the second camp comes up with a new thing in the next 20 years that's also awesome. We already have whatever we need. So

>> yeah.

>> Yeah. Let us just do our engineering,

>> right?

>> Yeah.

>> Yeah.

>> That's really good framing. And the way this manifests in the in the you know in the world is there's a data layer,

>> there's the intelligence layer which is where camp 1 is presumably producing a lot of great models and then there's the software layer where the users engage with.

>> Where do you think value will acrue if you were to design a 100 units of value across these three layers? The data layer, the intelligence layer and the software or the application layer. Where do you think value occurs in the next five years?

>> All right, this is a this is a tough question. I mean, I think the all those three layers actually are very fundamental. Yeah,

>> I thought you going to add a few more which are not influence semis but

>> yeah because I think I feel like the like as Ali was saying that the models are going to be available to all of us you know they are going to be commodity and it's going to hard to sort of see that it the more spend goes to them versus you know these layers on top

>> the but how do how do you like you know I it's hard to sort of come up with you know where the most value will and I also don't know if actually it changes from today's technology architecture where again like you know when you think about in a preAI world u any sort of like you know enterprise you know you know application and data systems you know you have you have data systems you do have I guess you don't have enough of that intelligent layer today and then you have the application layer so I so I guess you know some dollars will shift into it I know we do think that the intelligence layer is actually going to pretty thick one maybe you know it'll capture half of the enterprise value

>> anything to add Ali yeah no I think that you know yeah there are more layers in the stack depending on how you want to do it but I think as I said the LLM is a commodity as Arvin said you can get them like you know but that's not that doesn't mean those companies are not going to be valuable they can be very I mean TSMC is very valuable but I'm saying and they're going to be kind of like these fabike companies but but they're interchangeable and we've never seen something like that ever I have not during all these people just switch LLMs like in one day. That's not the case with your, you know, your iPhone versus Android or your Windows versus your Mac or your anything versus anything like you know you know Google Sheets versus Excel is like huge religious battle inside our company. but but LLM it's like you know because it's a commodity as I said it just speaks English or any language you like and you can and it gives you different answers every time. Might as well just try the cheaper one the cheaper commodity or the flight to smarter commodity. You can't even really tell the difference, can you? , so then what is special is the data that you have. Again, if your company has data that it has actually collected that your competitors do not have, like Glean is amazing, but if you remove all the data from Glean, it's there's no use to it, right? So, it's all about the data that you have. , and can you secure the data also? , so if we're going to have agents running around accessing this data like, oh, that's his HR data. Oh, here's the Purva's salary information. Oops, I blurped it out to all of you. Like, you know, like that's, you know, so how do you lock it down? how do you make sure that the there's governance there's you know there's also a lot of worry around can what if it's using a Chinese model? What if it's accessing this information? What if it's sharing this information with a competitor? What if it's interacting? So the governance security layer is going to be super super important. but I do think most of the value will acrue to the apps.

>> Yeah.

>> So it's kind of and I think that's common sense. It just I just don't know which apps. I do think Glean is amazing. I don't think Do you think of it as an app or I don't know but

>> now we see us as both app and a platform but

>> yes.

>> So I think it's a that's called an app platform. I do think it's amazing. Yeah. Because it has the potential to automate so much of the overhead inside of an organization like if you think about why do organizations have hundreds of thousands of employees you know some organizations or 50,000 20,000 a lot of it is the coordination overhead of like you know so many people have to communicate with each other. Hey, what happened? What did you exactly mean by this? Let's do a meeting where you explain to me I asked some questions. Let's or let's invite these other guys also and then write it down and then just the coordination overhead of organizations is massive,

>> right? It's like this n squared problem that you know everybody needs to communicate with everybody and they're communicating inside their siloed or chart but how do we get it across? So this like you know through docs and excel sheets and powerpoints and meetings is how we like move companies and organizations forward. So much of that can be augmented and be made more efficient with Glean. So that's why I think Glean is amazing. , but this is kind of like 2000.

>> Yeah.

>> And you ask what are the killer apps on the internet? By the way, back then we thought it's like Cisco routers,

>> you know,

>> portals maybe with thousands of links on them. Actually, I was like in I just started college and we knew that the future of internet would be portals which are these web pages with a hundred links on it and you just click on the right link. This was before Google search. But the f future of internet actually didn't look that way. It ended up being, you know, things like Facebook for friends and things like Airbnb for rentals and Uber for your cab industry and, you know, Twitter and so on. Those became great companies. So I don't know what those are for the future. They will pop up

>> and they will be extremely valuable. But okay. So does that mean that data bricks and glean then basically will die and there'll be a new set of companies? No. Back then there was actually an Amazon.com already in 98. it was already Google actually existed already in '98 and so on. Cisco by the way is still around and it's you know only a $300 billion company or something like that right so so it's not binary we'll see what happens I but I do think there's going to be really a lot of value will go to the future yeah you know apps that will emerge speak let's double click into that

>> the $300 billion companies of today add that layer software apps Salesforce service now a lot of talk about softwares being dead sat calls them the crud apps what is the future of this layer that today is called software that seems to be heading towards becoming a database. , and what do you see the the value acrew to those to these this part of the layer? Maybe start with you Arvin. Yeah, I think that's an oversimplification. like for example, even to say that Salesforce is you know is just a database. you know it's a it's a full sort of ecosystem of workflows and other applications you know that have sort of built on top of that infrastructure. So so I sort of like you know haven't really understood this concept of that you know you have this like a you know database you know where all your enterprise data is and then and then people can just go and create dynamic UI experiences on their own on top of that data on like you know every business can for example just create all the UI by themselves on this I don't think you know it's going to be happening like that because yes you know AI makes it easy for you to build you can have a database and you can build you can just talk to AI and create a UI an experience that that is you know exactly what you want it to be but most times you actually won't know what you want like you know I think a lot of like you know good thing about software companies is that they actually think about how to actually take that data but then present it in a way let you know make people interact with it or modify it in a way which sort of is natural and which you know drives you know, like more productivity from a human. So, so I think ultimately like software is an end to-end stack in my opinion. And all of these companies, you know, I don't think they're going away. I don't think, you know, they're going to relegate it to becoming a database.

>> Humans, you know, over the last 20 years, we got addicted to these screens. We scrunch over these screens and we would input this information with her with their keys with a drop down and hey, I met Irvin today and this is what I learned. It should really be, hey Chad, met with Arvin, this is what I learned. Remind me two days to catch up with him,

>> right? That will happen. That I think is going to happen. Yeah,

>> that will happen in the next couple years and even Glean you won't be wanted to type you want to talk to it but I think the big thing is data entry

>> how does the data appear in that database

>> and that's today not completely automated so you know just so like I think a company that would be well positioned to do that would actually kind of be Zoom you know and a lot of people don't think about it that way but Zoom is really should be the perfect data entry application right because that's where you're having all the conversations And that's all the information coming out. And if they could, you know, if it could work with and get extract the most important information, store it all, not in like a structured table, but like store that information in system of record.

>> If you had that, that would be the full disruption of the SAS. We have that right that's that's actually is one of the most common agents these days you know with clean which is you take these meeting recordings you figure out like you know what you talk to the customer what were the action items and then the agent goes updates the notes you know in sales force with that like these these kind of things are happening already. Yeah, meeting meetings is yeah is you know like we in clean we have this policy where we record every single meeting internal meeting external meeting if our customers allow cuz that's there's so much so much information you know in there

>> I I joined a meeting last week it was four humans and six AI note takers

>> and I heard about I think yesterday we were talking about 17 note takers in one of the you know discussions

>> it felt like the first you the first scene of a movie where the AI takes over. Clearly, there's a lot of sprawl. There's there's like almost too many tools and consolidation coming

>> at some point. But but maybe your guys' personal workflow, you know, you guys are CEOs in the age of AI, a lot of CIOS in the room, they've got more jobs than time on their hands. How are you using AI for both your personal self

>> and how are you driving your organizations, both large organizations to adopt AI and benefit from it? maybe give us a glimpse of your leadership in the age of AI. Maybe Ali, we start with you this time.

>> Yeah, I mean we have agents for all kinds of stuff that we use you know everything from you know we have agents that are really good at understanding our customers.

>> We have an agent ref is the name which

>> yeah if I want to understand anything about any like you know tell me best customer story on this like you know I told you about RBC Royal Bank Canada but I can just ask it. I need a use case. I'm going to get on stage. I need to talk about finance sector. Give me a use case that has these it'll like just find you all the information collect it. So it's really helpful for me for these kind of things like when I get on stage like this but also customer if you go into a customer meeting you know I want to tell customer X about their biggest competitor Y how they're using data bricks. Now maybe Y is not a comp is not using data bricks. So then I shouldn't use I should use Z which actually is using data bricks. Maybe that's like the number two competitor. How do I get this information super quickly? All of those are prepared at data bricks. So on the go to market side, a lot of this is being completely automated and we're using this

>> the marketing stack I already mentioned is heavily automated already like the a lot of the tasks that's happening in marketing. so we're seeing that stack that happening.

>> then there's engineering that's like a whole big thing like you know that's how we sort of and I think there's a whole change management and how to do it right. you know initial attempts at automate a lot of the software engineering at databics kind of failed even there's nothing wrong with AI

>> the problem is the humans and how we were organized but that's you know so those are like the two big orgs databicks is a big you know 6,000 person go to market org and 3 4,000 person R&D or and then there's some back office stuff those two already we're seeing heavy automation using agent for all kinds of the task

>> then there's back office so that finance and these functions finance is all on data bricks and it's all the forecasting all the sort of it's all moved to machine learning based but it took them a long time because they had their Excel models and they're very proud of them and they didn't want to you know but again there's a change management there we actually had an external data science team build the AI models

>> and then eventually they became good enough and now finance has taken those over and like now finance have kind of moved from Excel to Python

>> largely at data books but it was a journey because you know most of us speak

>> Excel similar thing is now happening to HR and other departments as well but I think they're like you know I think in general HR departments are like

>> you know even like they're not the closest to doing this kind of analytical work with you know Excel and so on so maybe that's not quite as far along but yes it's we're seeing it everywhere

>> yeah to add Arvin

>> same for us and I think I can share some of my own personal use with it like so one of our agents is daily prep agent which I really love because you know every morning

>> it tells me like you know what my day is going to be what I need to read what I need to prepare like most of the meetings you know I will not have context it actually brings you know like the plan for those meetings for me so that's that's one of my favorite agents you know that helps me feel more confident like you know for like how I'm going to do my meetings in the day the other one which I which I shared yesterday also the like you know I've changed my instinct And I think you know changing instincts you know take long time.

>> and you know when you're the CEO like you're the boss and everybody listens to you and you can just like you know whenever you have you know a small question curiously just go and ask somebody and they're going to like you know u put 30 people on the task to actually get that get that answer for me and this is

>> you got to have a prep meeting before the prep meeting.

>> Yeah. So all of that. So that so that's sort of like you know and so but it's sort of like for me it was easy. I just get to ask somebody and that you know I changed that because I knew I was actually causing like you know a lot of that was very expensive. So the so today like you know my instinct is to whenever I have curiosity whenever I have questions when I need to do data analysis when I need to write something you know my letter to the company every month all of those things you know like fundamentally I use you know AI of course you know clean in this case but to actually help me do my do my tasks yeah

>> more I think the you have to you have to sort of have that belief a lot of people won't do You have to have that belief that AI is a good collaborator. It's not going to do the work for you, but if you use it, you're going to actually produce better output eventually, even if you don't save time, you know, for the first, you know, first few months, but you're actually going to improve the quality of your output.

>> Fascinating. Well, this brings me to my favorite part of this conversation, which is rapid fire. Short answers are fine, long answers are welcome. , start with 12 months from now. Are the big AI companies that we know of today up or down? We'll start with OpenAI. 12 months from now, stocks up or down? Ali and then Arvin

>> up. And I'll say revenue will be up. I don't really understand how stocks work. Entropic

>> Ali Arvin

>> up.

>> Same.

>> Okay.

>> Let me let me Can I give you a little bit more?

>> Of course. because chat GPT is going to continue growing and it's on fire and it's what everybody uses.

>> so is Gemini by the way. And then entropic because more and more you know coding we've only like eaten into a small portion of that market. It just started. So

>> yeah. Is AI in a bubble? Yes or no?

>> There is an AI bubble. like saying like Okay. So then Glean is also in the bubble. Everybody's in the bubble. No, I would I would say there is a bubble. I would say those three camps.

>> Yeah. There is a super intelligence quest camp.

>> I would be very worried there. There's a second, the researchers doing the, you know, that's definitely not in a bubble. They're like the they're

>> sober.

>> Yeah, they're they're super sober and nobody cares about them. And then there's Right. And they're probably the ones that are right, unfortunately. And then there's the third camp, which is us trying to make this valuable. We're not in a bubble in a sense that we're not spending huge amounts of capital on what we are doing.

>> we're just trying to get actual economic value inside of this organization. So I don't think it's binary, but there is a bubble. I mean there are startups with zero revenue worth you know 10 20 30 billion that's a bubble

>> same I mean I think the there are quite a few companies where there's over optimism and valuations which are well ahead of the business that those companies have and like I guess you can say like you know compared to nonAI companies like of course AI companies do have higher multiples and but I think you know that's sort comes from that you know that there's a good reason for it you know because you know these are these AI companies are going to grow more than nonAI companies for sure.

>> Yeah my favorite game at Ultimate we ask our CEOs is a long short game is if you were to pick a company a product an idea that you're long that you think is going to be a bigger deal than it is today what is that and then short which is you know there's more sizzle than there's stake more hype than reality pick a long something that you're very optimistic on same order Ali and the Nurvvin I am very long on agents,

>> you know. I think I'm very long on speech

>> as an interaction. Like I think keyboards are kind of basically going to disappear

>> completely. We haven't actually nailed speech. I know. I know it feels like we have, but we haven't because you're still using your keyboard. So, as long as you're using a keyboard, we haven't nailed speech, but I think we're this close

>> to completely eliminating keyboard. So, I think that's that's a big one.

>> what's what would I say? It's like, you know, I do think coding is a little bit overhyped. I don't know if I would short it. It's I mean I think it's still the future.

>> so I think that's that's one of I think automating like customer service and support is a little bit overhyped.

>> So you know basically I think the things that the industry thinks are like amazing and we've made great progress we probably haven't done as much progress and then a lot of the other things that are being ignored I you know we're going to have breakthroughs in those. So

>> fascinating.

>> Yeah.

>> Yeah. And for me I think the products that are going to change the paradigm where instead of you building a product and you know expecting people to come to you if you understand your user your customer very deeply and actually bring AI to them that's the category that I'm excited about. I want I want to see more proactive AI products coming into the market next year. Yeah,

>> that's that is what is going to actually take it from a 5% of the users being power users to 100%.

>> Yeah. Yeah. Yeah. Your favorite AI tool that you use in your lives.

>> I think green is awesome. I mean, if that was not fair,

>> let's go.

>> so use it all the time. I actually a lot of the questions I would ask from the team. The thing you said you changed, I first ask lean and then see, you know, if it nails it or not, then if it doesn't, then I'll spin up a 30 person team to go spend a week and have three meetings and all that to get, you know, the explanation of some simple concept for me. But usually Glee nails it.

>> Yeah.

>> Yeah.

>> Well, for me, I'm excited about notetakers. I' I've used Granola myself and Fathom and a few others.

>> but note-taking is actually fascinating. I mean I think the I feel like you know if you if you take those notes and then if you utilize it the right way like for example what Ali was saying like you know that becomes the source of what then actually creates knowledge saves data in your systems that's going to change you know how companies work.

>> Yeah. You know in closing I'd love to get your vision for your companies. We'll start with Ali's favorite tool Glean. Congrats you just announced crossing a big milestone $200 million in revenue run rate. You've you're signing big deals, $10 million deals. You've got super users. I'm seeing you're seeing casual users. Paint us the vision for for Glean from here to a billion in revenue.

>> I think we're still doing annual planning, which also some, you know, AI companies are telling me that's that's so old school, but we're doing it regardless. We're doing

>> just because there's early startups like did you did you do annual planning when you started clean?

>> No.

>> No. So, so the but I think for us the thing that I'm most excited about again is so we think a lot about AI literacy and how do you get everybody along on this journey and we're not seeing it right now like glean is a heavily used product but still there's there's a big variance between the top users and the ones you know at the bottom

>> and that's what we want to change. so for the future for us is we want to be glean we want glean to be this very personal companion for every person in every company in the world. this companion with which you know is you know you have a very confidential relationship with this companion in the sense that whatever you ask this companion you know whatever communication you have with them you know it's it's fully privileged. Nobody else gets to see it. But this companion knows everything about you and your work life. It knows your day. It knows your week. it knows who you want to meet. you know in the day-to-day it knows your weekly goals. It knows what you know what things you're not good at or what your career ambitions are. And with all of that you know this personal companion is is sort of helping you now with your work. it you know hopefully takes majority of your tasks automatically. work you know works on them before you ask it to work on them. and that's so that's sort of the vision that we you know taking our product to. We have most of the found you know foundation for this in place already. today you have to come to clean to get most of that work done. In the future we want clean to actually come to you and do that work.

>> Fascinating. Well, we can keep going for a bit but I'm being called on time. Thank you so much for chopping it up with us. You got a lot of alpha lot of insights here. Really appreciate it.

>> Thank you. Thank you.

>> Thank you. Thank you.

>> All right, General. Thank you so much.